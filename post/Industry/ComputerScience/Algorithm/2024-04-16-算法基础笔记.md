---
html:
  offline: true
export_on_save:
  html: true
---

# 算法基础笔记

<br>

<br>

<br>

## 1 算法基础

<br>

### 1.1 以插入排序为例分析算法

<br>

我们考虑一个排序问题：
- 输入：$n$ 个数的一个序列 $a_1,\cdots,a_n$；
- 输出：输入序列的一个排列 $a_1',\cdots,a_n'$，满足 $a_1'\leq a_2'\cdots\leq a_n'$；

插入排序（insertion-sort）是一种解决以上排序问题的算法，其中的参数是一个数组 $A\left[1..n\right]$，包含长度为 $n$ 的要排列的一个序列，其伪代码如下：

> **算法 1.1-1 插入排序**
>
> ``` pseudocode
> procedure | insertion-sort(array A)
>           | n := The length of A
> 
> for j := 2 to n
>     key := A[j]
>     ;; Insert A[j] into the sorted sequence A[1..j-1]
>     i := j - 1
>     while i > 0 and A[i] > key
>         A[i + 1] := A[i]
>         i := i - 1
>     end while
>     A[i + 1] := key
> end for
> ```

由于算法最终要在计算机上实现，为了评判最有效的算法，需要度量算法执行的时间，因此必须要有能够使用的实现算法的模型包括描述所用的资源及其代价的模型。我们一般使用的是通用的单处理器计算模型——随机访问机（random-access machine, RAM）来实现算法。在 RAM 中，指令串行执行，没有并发操作。

RAM 模型包括真实计算机中常见的指令：
- 算术指令：加法、减法、乘法、除法、取余、向下取整、向上取整；
- 数据移动指令：装入、存储、复制；
- 控制指令：条件与无条件转移、子程序调用和返回。

以上所有指令所需的时间都是常量。

一般来说，算法需要的时间与输入的规模同步增长，所以通常把一个程序的运行时间描述成其输入规模的函数。输入规模的最佳定义依赖于研究的问题，例如输入是数组时，最自然的度量是**输入数组的项数**；输入是图时，最自然的度量是**图的顶点数和边数**。对于运行时间，我们一般采用这样的观点：执行每行伪代码需要常量时间，虽然一行与另一行可能需要不同数量的时间，但是我们假定第 $i$ 行的每次执行时间为 $c_i$，其中 $c_i$ 是一个常量。

下面我们分析插入排序的运行时间，设 $t_j$ 为伪代码中`while`语句运行的次数，注意当一个`for`或`while`循环按照通常的方式推出时，执行测试的次数比执行循环体的次数多 $1$。我们可以得到下面的分析表：

|行数|伪代码|运行时间|次数|
|:---:|:---:|:---:|:---:|
|1|`for j = 2 to A.length`|$c_1$|$n$|
|2|`key := A[j]`|$c_2$|$n-1$|
|3|注释|$0$|$n-1$|
|4|`i := j - 1`|$c_4$|$n-1$|
|5|`while i > 0 and A[i] > key`|$c_5$|$\sum_{j=2}^nt_j$|
|6|`A[i + 1] := A[i]`|$c_6$|$\sum_{j=2}^n(t_j-1)$|
|7|`i := i - 1`|$c_7$|$\sum_{j=2}^n(t_j-1)$|
|8|`A[i + 1] := key`|$c_8$|$n-1$|

该算法的运行时间是执行每条语句的运行时间之和，设总运行时间为 $T(n)$，则

$$
    \begin{aligned}
        T(n)=&c_1n+c_2(n-1)+c_4(n-1)+c_5\sum_{j=2}^nt_j\\
        &+c_6\sum_{j=2}^n(t_j-1)+c_7\sum_{j=2}^n(t_j-1)+c_8(n-1)
    \end{aligned}
$$

可以看到 $t_j$ 是与输入的序列有关的。我们可以分析它的最佳运行时间和最坏运行时间：
- 最佳运行时间：如果序列已经排好序，则出现最佳情况，这时可以看到对每个 $j=2,\cdots,n$，当 $i$ 取初值 $j-1$ 时，有 $A\left[j\right]\leq\text{key}$，此时`while`循环不执行，于是最佳运行时间为

    $$
        T_{\text{min}}(n)=an+b
    $$

    其中 $a,b$ 都与单行语句的运行时间 $c_i$ 有关，实际上 $a=c_1+c_2+c_4+c_5+c_8$，$b=-(c_2+c_4+c_5+c_8)$
- 最坏运行时间：如果序列是反序的，则出现最坏情况，这时必须将每个元素 $A\left[j\right]$ 和整个已经排序好的子序列 $A\left[1..j-1\right]$ 中的所有元素进行比较，所以有 $t_j=j$，注意到

    $$
        \sum_{j=2}^nj=\frac{n(n+1)}{2}-1,\quad\sum_{j=2}^n(j-1)=\frac{n(n-1)}{2}
    $$

    因此最坏运行时间为

    $$
        T_{\text{max}}(n)=an^2+bn+c
    $$

    其中 $a,b,c$ 都与单行语句的运行时间 $c_i$ 有关，实际上 $a=(c_5+c_6+c_7)/2$，$b=c_1+c_2+c_4+(c_5-c_6-c_7)/2+c_8$，$c=-(c_2+c_4+c_5+c_8)$

一般来说，我们只关心一个算法的最坏运行时间，这是因为一个算法的最坏运行时间给出了任何输入的运行时间的一个上界，确保该算法不会需要更长的时间。事实上，我们对一个算法的运行时间的**增长率**或者**增长量级**更加感兴趣，所以只用考虑算法的最坏运行时间的最重要项，例如插入排序的最坏运行时间可以记作 $\Theta(n^2)$。

如果一个算法的最坏运行时间具有比另一个算法的最坏运行时间更低的增长量级，那么我们通常认为前者比后者更有效。最坏运行时间也称为最坏时间复杂度，一般讨论的时间复杂度是最坏情况下的时间复杂度。

很多情况下我们还分析一个算法在运行过程中对内存的占用，与时间复杂度类似，我们称其为空间复杂度，并且一般也是最坏的运行内存。上述插入排序中只用到了存储输入的数组`A`和临时遍历变量`j`、`key`和`i`，所以空间复杂度为 $\Theta(n)$。

<br>

### 1.2 以归并排序为例设计算法

<br>

很多算法是递归的，所谓递归就是为了解决一个给定的问题，算法一次或者多次递归地调用其自身以解决相关的子问题。这种算法使用到了**分治法**的思想：将原问题分解为几个规模较小但是类似于原问题的子问题，递归地求解这些子问题，然后再合并这些子问题的解来建立原问题的解。

解决 1.1 中的排序问题还有一种归并排序算法，该算法遵循分治法的思想：
- 分解待排序的 $n$ 个元素的序列成各具 $n/2$ 个元素的两个子序列；
- 使用归并排序递归地排序两个子序列；
- 合并两个已排序的子序列产生已排序的答案。我们通过调用一个辅助过程 $\text{MERGE}(A,p,q,r)$ 来完成合并，其中 $A$ 是一个数组，$p,q,r$ 分别是数组元素的索引，满足 $p\leq q<r$。设该过程中子数组 $A\left[p..q\right]$ 与 $A\left[q+1..r\right]$ 都已经排好序。合并过程如下：首先将子数组复制到新的数组 $L\left[1..q-p+1\right]$ 与 $R\left[1..r-q\right]$ 中，并向两个数组的最后元素中添加一个**标记元素**，该标记元素在任何比较过程中都是最大的，在伪代码中可以表示为 $\infty$；设 $i,j$ 分别为指向数组 $L,R$ 的读取索引，比较 $L\left[i\right]$ 和 $R\left[j\right]$ 的大小，设 $k$ 为指向数组 $A$ 的读取索引，将较小的元素复制回原先的数组元素 $A\left[k\right]$，读取索引 $k$ 后移一位，较小元素对应的读取索引后移一位，重复该步骤，直到两个读取索引都读到标记元素。

> **算法 1.2-1 归并排序**
>
> ``` pseudocode
> procedure | merge-sort(A, p, r)
>
> if p < r
>     q := FLOOR((p + r) / 2)
>     merge-sort(A, p, q)
>     merge-sort(A, q + 1, r)
>
>     // merge(A, p, q, r)
>     n_1 := q - p + 1
>     n_2 := r - q
>     let L[1..n_1+1] and R[1..n_2+1] be new arrays
>     for i := 1 to n_1
>         L[i] := A[p + i - 1]
>     for j := 1 to n_2
>         R[j] := A[q + j]
>     L[n_1 + 1] = INFTY
>     R[n_2 + 1] = INFTY
>     i := 1
>     j := 1
>     for k := p to r
>         if L[i] <= R[j]
>             A[k] := L[i]
>             i := i + 1
>         else 
>             A[k] := R[j]
>             j := j + 1
> ```

我们可以说明 $\text{MERGE}(A,p,q,r)$ 过程的时间复杂度为 $\Theta(n)$，其中 $n=r-p+1$，注意到归并过程中复制需要的时间为 $n_1+n_2=n$，最后的`for`循环需要的时间为 $r-p+1=n$，因此归并花费的时间为 $\Theta(n)$。

当一个算法包含对其自身的递归调用时，我们可以用**递归方程**或**递归式**来描述其时间复杂度。我们假设 $T(n)$ 是一个规模为 $n$ 的问题的运行时间，如果问题规模足够小，对于某个常量 $c$，$n\leq c$，直接求解需要常量时间，记作 $\Theta(1)$。假设将原问题分解成 $a$ 个子问题，每个子问题的规模是原问题的 $1/b$（在归并排序中，$a=b=2$），为了求解一个规模为 $n/b$ 的问题，需要花费 $T(n/b)$ 的时间，设分解成子问题需要 $D(n)$ 的时间，将子问题的解合并成原问题的解需要 $C(n)$ 的时间，因此

$$
    T(n)=\begin{cases}
        \Theta(1)&n\leq c\\[3pt]
        \displaystyle aT\left(\frac{n}{b}\right)+D(n)+C(n)&\text{otherwise}
    \end{cases}
$$

虽然归并排序的规模不是偶数时也能正常工作，但为了简化问题，我们设 $n=2^k$，其中 $k\in\mathbb{Z}$，这样每次分解子问题都可以得到规模刚好为 $n/2$ 的子问题，在第2节中将说明这个假设不影响其他情形下时间复杂度的增长量级。

对于归并排序，我们知道只有当 $n=1$ 时递归才停止，合并才开始回溯。当有 $n>1$ 个元素时，我们将运行时间分解如下：
- 分解步骤仅需要计算子数组的中间位置，是常量时间，$D(n)=\Theta(1)$；
- 递归地求解两个子问题，将贡献 $2T(n/2)$ 的运行时间；
- 之前提过合并过程 $\text{MERGE}(A,p,q,r)$ 花费的时间为 $C(n)=\Theta(n)$。

因此

$$
    T(n)=\begin{cases}
        \Theta(1)&n=1\\[3pt]
        \displaystyle 2T\left(\frac{n}{2}\right)+\Theta(n)&n>1
    \end{cases}
$$

我们设 $\Theta(1)=c$，$\Theta(n)=cn$，并且将递归过程画成递归树的形式：

``` figure
 -                     cn
 |                   /    \
 |                  /      \
 |                cn/2     cn/2
logn + 1         /   \     /   \
 |            cn/4  cn/4  cn/4  cn/4
 |           .......................
 |            | | | | | ... | | | |
 -            c c c c c ... c c c c
```

注意在每层递归树中，递归的合并的贡献运行时间均为 $cn$，因此总运行时间为 $cn\log n+cn$，即归并排序的时间复杂度为 $\Theta(n\log n)$。所以我们说归并排序要优于插入排序。

<br>

### 1.3 函数的增长

<br>

当输入规模足够大，使得只有运行时间的增长量级起到了最重要的作用时，我们就要研究算法的渐进效率，以下是一些渐进符号：
- 设 $\exists c_1,c_2,n_0>0,\forall n\geq n_0,$，则 $\Theta(g(n))$ 用来表示以下函数的集合：

    $$
        \Theta(g(n))=\{f(n):0\leq c_1g(n)\leq f(n)\leq c_2g(n)\}
    $$

    我们称 $g(n)$ 是 $f(n)$ 的渐进紧确界，每个成员 $f(n)\in\Theta(g(n))$ 均渐进非负，函数 $g(n)$ 本身必须渐进非负，$\Theta$ 符号给出了一个上界和一个下界；
- 设 $\exists c,n_0>0,\forall n\geq n_0$，则 $O(g(n))$ 用来表示以下函数的集合：

    $$
        O(g(n))=\{f(n):0\leq f(n)\leq cg(n)\}
    $$

    我们称 $g(n)$ 是 $f(n)$ 的渐进上界，我们可以看出符号 $\Theta$ 比 $O$ 更加强大，我们可以写作 $\Theta(g(n))\subseteq O(g(n))$，在大多数情况下常用的是 $O$ 符号，因为它已经给出了最坏时间复杂度的上界，用于研究算法一般是足够的（在一些算法文献中可能会混用 $\Theta$ 和 $O$，这是以前不规范的做法）；
- 设 $\exists c,n_0>0,\forall n\geq n_0$，则 $\Omega(g(n))$ 用来表示以下函数的集合：

    $$
        \Omega(g(n))=\{f(n):0\leq cg(n)\leq f(n)\}
    $$

    我们称 $g(n)$ 是 $f(n)$ 的渐进下界，根据前面的定义，我们可以知道如果 $f(n)\in\Theta(g(n))$，当且仅当 $f(n)\in O(g(n))$ 且 $f(n)\in\Omega(g(n))$；
- 设 $\exists n_0>0,\forall c>0,n\geq n_0$，则 $o(g(n))$ 用来表示以下函数的集合：

    $$
        o(g(n))=\{f(n):0\leq f(n)<cg(n)\}
    $$

    我们称 $f(n)$ 渐进小于 $g(n)$， $o(g(n))$ 的界 $0\leq f(n)<cg(n)$ 是对所有常数 $c$ 都成立的，因此我们有

    $$
        \lim_{n\to\infty}\frac{f(n)}{g(n)}=0,\quad g(n)>0,f(n)\geq 0
    $$

- 设 $\exists n_0>0,\forall c>0,n\geq n_0$，则 $\omega(g(n))$ 用来表示以下函数的集合：

    $$
        \omega(g(n))=\{f(n):0\leq cg(n)<f(n)\}
    $$

    我们称 $f(n)$ 渐进大于 $g(n)$，$\omega(g(n))$ 的界 $0\leq cg(n)<f(n)$ 是对所有常数 $c$ 都成立的，因此我们有

    $$
        \lim_{n\to\infty}\frac{g(n)}{f(n)}=0,\quad f(n)>0,g(n)\geq 0
    $$

<br>

<br>

<br>

## 2 递归与分治策略

<br>

在 1.2 节中以归并排序为例分析了含有分治思想的算法，除了常见的递归式，某些算法也可能用到递归不等式，例如 $T(n)\leq 2T(n/2)+\Theta(n)$，这种递归不等式仅描述了 $T(n)$ 的上界，因此可以用 $O$ 来描述其解；类似地，对于 $T(n)\geq 2T(n/2)+\Theta(n)$，这种递归不等式仅描述了 $T(n)$ 的下界，因此可以用 $\Omega$ 来描述其解。

我们常常忽略一些边界问题，例如二分过程中 $n$ 可能是一个奇数，对于 1.2 节中的归并排序，实际上的递归式应该写成：

$$
    T(n)=\begin{cases}
        \Theta(1)&n=1\\[3pt]
        \displaystyle T\left(\left\lfloor\frac{n}{2}\right\rfloor\right)+T\left(\left\lceil\frac{n}{2}\right\rceil\right)+\Theta(n)&n>1
    \end{cases}
$$